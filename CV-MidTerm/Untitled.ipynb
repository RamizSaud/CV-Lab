{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b256f4-6a43-48cb-ac1d-e37edfca611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescaling for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f39761-be6c-426d-8acc-2053ec9b3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the target directory\n",
    "        target_size=(150, 150),  # All images will be resized\n",
    "        batch_size=32,\n",
    "        class_mode='binary') # Use 'categorical' for multi-class classification\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f109ebd-c817-4c85-999c-64a8beeca914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "images = [train_generator[0][0][i] for i in range(5)]\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed30487-dcdb-4b9f-8083-e0f905dd483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Use 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf740e2-5def-4984-93f1-6a056377be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # total train images / batch size\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # total validation images / batch size\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937217e-d234-4d75-b6f0-91d15ad15992",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = model.evaluate(validation_generator)\n",
    "print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbd253-73d1-4661-80f0-defd77fc9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming `test_images` is your dataset for predictions\n",
    "predictions = model.predict(test_images)\n",
    "predicted_class_indices = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# For binary classification\n",
    "# predicted_class_indices = (predictions > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5989b7-788c-4bf7-b102-516e2210cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, target_size=(150, 150)):\n",
    "    # Load the image\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = img_to_array(img)\n",
    "    # Scale the image pixels to be between 0 and 1\n",
    "    img_array /= 255.0\n",
    "    # Expand the dimensions so the input array shape becomes (1, height, width, channels)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abdc11-ba30-4a88-a092-f973eb7eaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\", ...]  # List of image paths\n",
    "preprocessed_images = np.vstack([preprocess_image(path) for path in test_image_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee9fc9-50b4-42d2-bf35-9a7f32da019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of test image paths\n",
    "test_image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\", ...]\n",
    "\n",
    "# Preprocess the images\n",
    "preprocessed_images = np.vstack([preprocess_image(path) for path in test_image_paths])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(preprocessed_images)\n",
    "\n",
    "# Interpret predictions\n",
    "# For binary classification:\n",
    "predicted_classes_binary = (predictions > 0.5).astype(int)\n",
    "# For multi-class classification:\n",
    "predicted_classes_multi = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Now you can use `predicted_classes_binary` or `predicted_classes_multi` depending on your task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3443dd-1ee1-4bb7-aa76-60a6d5c37e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_with_predictions(images, true_labels, predictions, class_names=['Class 0', 'Class 1'], n=5):\n",
    "    \"\"\"\n",
    "    Visualize the first n images with their predicted and true labels.\n",
    "    \n",
    "    :param images: The array of preprocessed images.\n",
    "    :param true_labels: The true labels for the images.\n",
    "    :param predictions: The model's predicted probabilities for class 1.\n",
    "    :param class_names: The names of the classes.\n",
    "    :param n: The number of images to display.\n",
    "    \"\"\"\n",
    "    # Select the first n images, true labels, and predictions\n",
    "    images = images[:n]\n",
    "    true_labels = true_labels[:n]\n",
    "    predictions = predictions[:n]\n",
    "    \n",
    "    # Set up the matplotlib figure and axes\n",
    "    plt.figure(figsize=(2*n, 4))\n",
    "    for i in range(n):\n",
    "        # Display images\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')  # Adjust color map or remove it depending on your images\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Get predicted label by checking if prediction > 0.5\n",
    "        pred_label = 1 if predictions[i] > 0.5 else 0\n",
    "        color = 'green' if pred_label == true_labels[i] else 'red'\n",
    "        \n",
    "        # Title will show predicted and true labels\n",
    "        plt.title(f'Pred: {class_names[pred_label]}\\nTrue: {class_names[true_labels[i]]}', color=color)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming `preprocessed_images` is your array of test images and is not normalized between 0 and 1 for visualization purposes\n",
    "# If your `preprocessed_images` were normalized, you might need to denormalize them for visualization.\n",
    "plot_images_with_predictions(preprocessed_images, true_labels, predictions[:,0], class_names=['Not Class 1', 'Class 1'], n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7f4fd-40d9-40ae-9202-0838438add84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# true_labels: The true labels for your test dataset\n",
    "# predicted_classes: The predicted labels for your test dataset (use predicted_classes_binary or predicted_classes_multi)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "precision = precision_score(true_labels, predicted_classes, average='binary')  # For binary classification, for multi-class use 'micro', 'macro', or 'weighted'\n",
    "recall = recall_score(true_labels, predicted_classes, average='binary')  # Same as precision\n",
    "f1 = f1_score(true_labels, predicted_classes, average='binary')  # Same as precision\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176ae5b-e024-44ac-9443-f871a23d4157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `validation_generator` is your data generator\n",
    "\n",
    "# Initialize an empty array to store the true labels\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over the generator to extract true labels\n",
    "for _, labels_batch in validation_generator:\n",
    "    true_labels.extend(labels_batch)\n",
    "    # Check if we've gone through all data\n",
    "    if len(true_labels) >= validation_generator.samples:\n",
    "        break\n",
    "\n",
    "# Convert the list of true labels to a numpy array for further processing\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# If your labels are one-hot encoded, you might want to convert them to integer labels\n",
    "# true_labels = np.argmax(true_labels, axis=1)  # Uncomment this line if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c4323-0c59-4dc5-9bb2-02e94564115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting probabilities for the positive class\n",
    "predictions = model.predict(images)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ff753-31ec-42e3-b859-9bf0a6941745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi-class classification\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520022cc-39e5-4ef9-a771-0734408391d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `validation_generator` is your data generator\n",
    "\n",
    "# Initialize lists to store the images and their true labels\n",
    "images = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over the generator to extract images and true labels\n",
    "for images_batch, labels_batch in validation_generator:\n",
    "    images.extend(images_batch)\n",
    "    true_labels.extend(labels_batch)\n",
    "    # Check if we've gone through all data\n",
    "    if len(true_labels) >= validation_generator.samples:\n",
    "        break\n",
    "\n",
    "# At this point, 'images' is a list of numpy arrays (the images), and 'true_labels' is a list of labels\n",
    "\n",
    "# Optionally, convert lists to numpy arrays for further processing\n",
    "images = np.array(images)\n",
    "true_labels = np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c84b3-5e8e-4e34-8882-db4ff95959a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting probabilities for the positive class\n",
    "predictions = model.predict(images)\n",
    "\n",
    "# Converting probabilities to class labels based on a threshold\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072bf4e-f1ac-450a-babb-d75f79f8622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi-class classification\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198db8f-74b9-4d1c-974d-84c73e52c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8a578-4f48-40c0-a333-d2af91c2f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f5eea-0b72-4c1d-b413-e36b94eae75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, target_size=(150, 150)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # Normalize the image\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7eb520-8fce-4542-954c-bf7df6e56f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a function to convert labels to numeric format\n",
    "def convert_labels(labels):\n",
    "    # Implement label conversion here\n",
    "    return numeric_labels\n",
    "\n",
    "# Preprocess images\n",
    "train_images = np.array([preprocess_image(path) for path in train_df['image_path']])\n",
    "valid_images = np.array([preprocess_image(path) for path in valid_df['image_path']])\n",
    "\n",
    "# Convert labels\n",
    "train_labels = convert_labels(train_df['label'])\n",
    "valid_labels = convert_labels(valid_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d5425-f5d6-4012-9846-416e61046c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca5b2e-3710-49ff-a3d4-c83aa061ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(valid_images)\n",
    "# Convert predictions to labels based on your problem\n",
    "\n",
    "# Evaluate the model\n",
    "# Use accuracy_score, precision_score, recall_score, f1_score as shown previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59b971-53c6-407c-92ac-943a00e28296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e0b9f-49b3-4d31-98e2-f2794192a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(valid_labels, predicted_labels)\n",
    "precision = precision_score(valid_labels, predicted_labels, average='binary')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(valid_labels, predicted_labels, average='binary')  # Use 'macro' or 'weighted' for multi-class\n",
    "f1 = f1_score(valid_labels, predicted_labels, average='binary')  # Use 'macro' or 'weighted' for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dd3fe-cde6-48e6-9971-a56ae9c30069",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(valid_labels, predicted_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f5eae-a015-4414-a075-0aff7ed708fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, ...)  # Add any other augmentations\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Adjust based on your model's expected input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  # or 'categorical' for multi-class classification\n",
    "    color_mode='grayscale'  # Load images in grayscale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374f923-7d32-428e-9645-61795d8732b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(image_path, target_size=(150, 150), color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377a0c5-f38d-4e41-a4ec-da20d1ca82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),  # Note the input shape is (150, 150, 1) for grayscale\n",
    "    MaxPooling2D(2, 2),\n",
    "    # Add more layers as needed\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or Dense(num_classes, activation='softmax') for multi-class\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574094d-de6f-4afa-a1fb-ad5d9cd2bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),  # Note the input shape is (150, 150, 1) for grayscale\n",
    "    MaxPooling2D(2, 2),\n",
    "    # Add more layers as needed\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or Dense(num_classes, activation='softmax') for multi-class\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d10c9-880b-4671-a042-ab30fbc878f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(grayscale_image.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e4e12-c300-452c-a431-33d4b9dd9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1aef0f-bdbe-44f0-bd35-acd4847f56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2aa0e-0172-4153-9006-cc0bef75a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986bc67-c8d2-4077-991b-277ce67fa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# Add an output layer with softmax activation\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138adcc6-4c1d-4970-b07d-e2e148ce5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdce8d5-21f9-4bf5-95bc-471123fba0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_directory,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb631dc7-3ddb-4bde-8485-f2bc28e9a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.samples // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d30bf-491e-4b2d-bdb8-f3c9c4d5a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze some layers in the base model\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model (necessary after making modifications to the layers)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Very low learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.samples // batch_size,\n",
    "          epochs=fine_tune_epochs,  # Number of epochs to fine-tune for\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a19feb-727c-491a-a5cb-1a6a990fbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d88c8-5ba9-4233-aa6a-8add4f7123d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ffce7-11f2-4f12-9123-a13955725734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)  # Adjust depending on your model's expected input\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226c3f8-25fd-4a88-b2fa-63a4f38a8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([preprocess_image(path) for path in train_df['image_path']])\n",
    "X_valid = np.array([preprocess_image(path) for path in valid_df['image_path']])\n",
    "\n",
    "# Assuming class labels are categorical and need to be one-hot encoded\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train = encoder.fit_transform(train_df[['class']])\n",
    "y_valid = encoder.transform(valid_df[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b68931-6d3d-4895-a6bc-2fc020389a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484b4c6-b090-4e30-a457-eb3aab3775c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Change the last layer according to your problem\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac6b1cd-8e66-4711-9bea-187f293e6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # Normalize images to [0, 1]\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222439f-8766-4147-b346-b3b2fbfc7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert image paths to preprocessed image data\n",
    "X = np.array([preprocess_image(path) for path in df['image_path']])\n",
    "\n",
    "# Convert labels (assuming binary classification for simplicity)\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e92e6-e1c9-4188-aa05-07e85e8ffe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # or 'categorical_crossentropy' for multi-class\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5876f21-6cd2-4ca8-a709-589b9f50e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Split for training and validation\n",
    ")\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "datagen.fit(X)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow()\n",
    "model.fit(datagen.flow(X, y, batch_size=32, subset='training'),\n",
    "          validation_data=datagen.flow(X, y, batch_size=32, subset='validation'),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b51b0-4d95-4b32-a4d9-1d257bf4428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # Normalize images to [0, 1]\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae012c4e-5026-4cee-8f47-6caea849b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([preprocess_image(path) for path in df['image_path']])\n",
    "\n",
    "# Assuming binary classification. Use appropriate encoding for multi-class scenarios.\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82002e-d522-42c3-8ae3-467214ebd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb1750-ec99-46b8-9309-38c21ac3e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc98f7c-405a-4033-9634-78428da10e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
